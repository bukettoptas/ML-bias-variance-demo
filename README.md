# ğŸ“Š Linear Regresyon: SÄ±fÄ±rdan Ä°leri Seviye

> **Makine Ã–ÄŸrenmesi'nin Temel TaÅŸÄ±: Linear Regresyon Ders NotlarÄ±**
> 
> *HazÄ±rlayan: Dr. Buket ToptaÅŸ*  
> *Tarih: 2025*

---
---
Bu adrese tÄ±klayarak index.html notlarÄ±nÄ± gÃ¶rebilirsiniz: https://bukettoptas.github.io/ML-bias-variance-demo/
## ğŸ¯ GiriÅŸ

Linear Regresyon, **makine Ã¶ÄŸrenmesinin alfabesi**dir. Ä°ki deÄŸiÅŸken arasÄ±ndaki doÄŸrusal iliÅŸkiyi modelleyen bu algoritma, karmaÅŸÄ±k modellerin temelini oluÅŸturur.

### ğŸ“ Bu Derste Ã–ÄŸrenecekleriniz

- âœ… Linear regresyonun matematiksel temelleri
- âœ… Python ve Sklearn ile uygulama
- âœ… Model performansÄ±nÄ± deÄŸerlendirme
- âœ… Overfitting ve underfitting kavramlarÄ±
- âœ… GerÃ§ek dÃ¼nya problemlerini Ã§Ã¶zme

### ğŸ“‹ Ã–n KoÅŸullar

```python
# Gerekli kÃ¼tÃ¼phaneler
numpy>=1.21.0
matplotlib>=3.4.0
scikit-learn>=1.0.0
pandas>=1.3.0
seaborn>=0.11.0
```

---

## ğŸ” Linear Regresyon Nedir?

Linear regresyon, **baÄŸÄ±mlÄ± deÄŸiÅŸken (y)** ile bir veya daha fazla **baÄŸÄ±msÄ±z deÄŸiÅŸken (x)** arasÄ±ndaki **doÄŸrusal iliÅŸkiyi** modelleyen istatistiksel bir yÃ¶ntemdir.

### ğŸ“ Basit FormÃ¼l

```
y = mx + b
```

Burada:
- **y**: Tahmin etmek istediÄŸimiz deÄŸer (baÄŸÄ±mlÄ± deÄŸiÅŸken)
- **x**: BildiÄŸimiz deÄŸer (baÄŸÄ±msÄ±z deÄŸiÅŸken)
- **m**: EÄŸim (slope) - x deÄŸiÅŸince y ne kadar deÄŸiÅŸir?
- **b**: Kesim noktasÄ± (intercept) - x=0 olduÄŸunda y'nin deÄŸeri

### ğŸ¯ Ã–rnek Senaryo: Dondurma SatÄ±ÅŸlarÄ±

> Ahmet Amca bir sahil kasabasÄ±nda dondurma satÄ±yor. SÄ±caklÄ±k arttÄ±kÃ§a satÄ±ÅŸlarÄ± da artÄ±yor. YarÄ±n hava 35Â°C olacaksa, kaÃ§ dondurma hazÄ±rlamalÄ±?

| SÄ±caklÄ±k (Â°C) | SatÄ±ÅŸ (Adet) |
|---------------|--------------|
| 20            | 30           |
| 22            | 35           |
| 25            | 45           |
| 28            | 55           |
| 30            | 60           |
| 32            | 70           |
| 35            | 80           |

**Soru:** 35Â°C'de kaÃ§ dondurma satÄ±lÄ±r?

---

## ğŸ“Š Matematiksel Temel

### En KÃ¼Ã§Ã¼k Kareler YÃ¶ntemi (Ordinary Least Squares - OLS)

Linear regresyon, **hata karelerinin toplamÄ±nÄ± minimize eden** en iyi doÄŸruyu bulur.

#### EÄŸim (m) Hesaplama

```
m = Î£[(xi - xÌ„)(yi - È³)] / Î£[(xi - xÌ„)Â²]
```

#### Kesim (b) Hesaplama

```
b = È³ - m Ã— xÌ„
```

Burada:
- `xÌ„` = Ortalama x deÄŸeri
- `È³` = Ortalama y deÄŸeri
- `Î£` = Toplam sembolÃ¼

### ğŸ§® AdÄ±m AdÄ±m Hesaplama

```python
import numpy as np

# Veri
sicaklik = np.array([20, 22, 25, 28, 30, 32, 35])
satis = np.array([30, 35, 45, 55, 60, 70, 80])

# Ortalamalar
x_mean = np.mean(sicaklik)  # 27.43
y_mean = np.mean(satis)      # 53.57

# EÄŸim (m)
numerator = np.sum((sicaklik - x_mean) * (satis - y_mean))
denominator = np.sum((sicaklik - x_mean) ** 2)
m = numerator / denominator  # 3.42

# Kesim (b)
b = y_mean - m * x_mean      # -40.14

print(f"Denklem: y = {m:.2f}x + {b:.2f}")
# Output: y = 3.42x + -40.14
```

**SonuÃ§:** Her 1Â°C artÄ±ÅŸta satÄ±ÅŸ ~3.42 adet artÄ±yor!

---

## ğŸ¯ Performans Metrikleri

### 1. RÂ² (R-Squared) - Determinasyon KatsayÄ±sÄ±

**Ne Ã¶lÃ§er?** Modelin veriyi ne kadar iyi aÃ§Ä±kladÄ±ÄŸÄ±

```python
r2 = r2_score(y_true, y_pred)
```

**Yorumlama:**
- **RÂ² = 1.0**: MÃ¼kemmel model (tÃ¼m varyansÄ± aÃ§Ä±klÄ±yor)
- **RÂ² = 0.8-0.9**: Ã‡ok iyi
- **RÂ² = 0.6-0.7**: Ä°yi
- **RÂ² < 0.5**: ZayÄ±f
- **RÂ² < 0**: Modeliniz ortalamanÄ±n altÄ±nda!

### 2. MSE (Mean Squared Error)

**Ne Ã¶lÃ§er?** HatalarÄ±n karelerinin ortalamasÄ±

```python
mse = mean_squared_error(y_true, y_pred)
```

**Ã–zellikler:**
- BÃ¼yÃ¼k hatalarÄ± daha Ã§ok cezalandÄ±rÄ±r
- Asla negatif olamaz
- Orijinal birimle aynÄ± deÄŸil (kare)

### 3. RMSE (Root Mean Squared Error)

**Ne Ã¶lÃ§er?** MSE'nin karekÃ¶kÃ¼ (orijinal birimle)

```python
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
```

**AvantajlarÄ±:**
- Orijinal birimle Ã§alÄ±ÅŸÄ±r (yorumlamasÄ± kolay)
- Outlier'lara duyarlÄ±

### 4. MAE (Mean Absolute Error)

**Ne Ã¶lÃ§er?** HatalarÄ±n mutlak deÄŸerlerinin ortalamasÄ±

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
```

**AvantajlarÄ±:**
- Outlier'lara daha az duyarlÄ±
- Basit yorumlama

## ğŸš€ Ä°leri Seviye Konular

### 1. Polynomial Regression (Polinom Regresyon)

DoÄŸrusal olmayan iliÅŸkiler iÃ§in:

```python
from sklearn.preprocessing import PolynomialFeatures

# Polinom Ã¶zellikleri oluÅŸtur (derece=2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

# Model
model = LinearRegression()
model.fit(X_poly, y)

# xÂ² ve xy terimleri otomatik eklendi!
```

### 2. Regularization (Ridge & Lasso)

Overfitting'i Ã¶nlemek iÃ§in:

```python
from sklearn.linear_model import Ridge, Lasso

# Ridge (L2 Regularization)
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

# Lasso (L1 Regularization)
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
```

### 3. Feature Scaling

Ã–zellikleri normalize etme:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

model = LinearRegression()
model.fit(X_scaled, y)
```

### 4. Cross-Validation

Modeli gÃ¼venilir ÅŸekilde deÄŸerlendirme:

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5, scoring='r2')
print(f"Ortalama RÂ²: {scores.mean():.4f} (Â±{scores.std():.4f})")
```

---


### ğŸŒ Online Kaynaklar
- [Scikit-learn DokÃ¼mantasyonu](https://scikit-learn.org/)
- [Khan Academy - Statistics](https://www.khanacademy.org/math/statistics-probability)
- [StatQuest YouTube](https://www.youtube.com/c/joshstarmer)


## ğŸ¤ KatkÄ±da Bulunma

Bu proje aÃ§Ä±k kaynak kodludur. KatkÄ±larÄ±nÄ±zÄ± bekliyoruz!

```bash
# Repo'yu fork edin
git clone https://github.com/bukettoptas/linear-regression-tutorial.git

# Branch oluÅŸturun
git checkout -b feature/yeni-Ã¶zellik

# Commit yapÄ±n
git commit -m "Yeni Ã¶zellik eklendi"

# Push edin
git push origin feature/yeni-Ã¶zellik

# Pull request aÃ§Ä±n
```

---


**Buket ToptaÅŸ**  
ğŸ’¼ LinkedIn: [linkedin.com/in/bukettoptas]  
ğŸ™ GitHub: [@bukettoptas](https://github.com/bukettoptas)

---

<div align="center">

**â­ Bu repo iÅŸinize yaradÄ±ysa yÄ±ldÄ±z vermeyi unutmayÄ±n! â­**

Made with â¤ï¸ for Machine Learning Students

</div>
